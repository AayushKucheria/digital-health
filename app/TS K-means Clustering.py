# -*- coding: utf-8 -*-
"""Futurice Digital Healthcare 3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jDNS-UMNCSLa4mE66IwM5w97AY-yWllH

Instal Libraries
"""

!pip install PyWavelets
!pip install tslearn

"""Import common Data Science-Statistics Library"""

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import pandas.testing as tm
from matplotlib import pyplot
import os
import random
plt.rcParams.update({'figure.figsize': (25,12)})
plt.rcParams['axes.labelsize'] = 25
plt.rcParams['xtick.labelsize'] = 15
plt.rcParams['ytick.labelsize'] = 15
plt.rcParams['text.color'] = 'k'

"""Import Data Science library"""

import pywt
from scipy.fft import fft, ifft
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
from tslearn.clustering import TimeSeriesKMeans
from sklearn.metrics import confusion_matrix

"""Import Deep Learning library"""

import torch
import torch.nn as nn
import torch.nn.functional as Func

"""Import data"""

temp_datasets = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]
folders = ["Z", "O", "N", "F", "S"]
for folder in folders:
    i = folders.index(folder)
    temp_data = pd.DataFrame()
    for filename in sorted(os.listdir(folder)):
        temp = pd.read_csv(folder + "/" + filename, sep = "\n", header=None).to_numpy().flatten()
        temp_data[filename] = temp
    temp_datasets[i] = temp_data
F = temp_datasets[3]; N = temp_datasets[2]; O = temp_datasets[1]; S = temp_datasets[4]; Z = temp_datasets[0]
datasets = [Z, O, N, F, S]
colorE = ['b','r','g','y','k','m', 'c']
labeled = ['Z', 'O', 'N', 'F', 'S']
fig, ax = plt.subplots(5, 1, figsize=(50, 60))
for i in range(5):
    ax[i].plot(datasets[i].iloc[:, 0], colorE[i] ,linewidth = 3, label = labeled[i])
    ax[i].grid ()

def DWT_db2(data):
    (A1, D1) = pywt.dwt(data, 'db2')
    (A2, D2) = pywt.dwt(A1, 'db2')
    return (D1[0:1025].reshape(-1, 1), D2[0:1025].reshape(-1, 1), A2[0:1025].reshape(-1, 1))

DWTed_train = []
DWTed_test = []
train = []
test = []
for dataset in datasets:
    temp_DWTed_train = []
    temp_DWTed_test = []
    trainset = dataset.iloc[:, : 80]
    testset = dataset.iloc[:,-20:]
    for i in range(80):
        data = trainset.iloc[:, i]
        D1, D2, A2 = DWT_db2(data)
        DWTed_train.append(D1); DWTed_train.append(D2); DWTed_train.append(A2)
        train.append(data[0:1024].to_numpy().reshape(-1, 1))
        train.append(data[1024:2048].to_numpy().reshape(-1, 1))
        train.append(data[2048:3072].to_numpy().reshape(-1, 1))
        train.append(data[3072:4096].to_numpy().reshape(-1, 1))
    for i in range(20):
        data = testset.iloc[:, i]
        D1, D2, A2 = DWT_db2(data)
        DWTed_test.append(D1); DWTed_test.append(D1); DWTed_test.append(A2)
        test.append(data[0:1000].to_numpy().reshape(-1, 1))
        test.append(data[1024:2048].to_numpy().reshape(-1, 1))
        test.append(data[2048:3072].to_numpy().reshape(-1, 1))
        test.append(data[3072:4096].to_numpy().reshape(-1, 1))
#DWTed_test = random.sample(DWTed_test, len(DWTed_test))
#test = random.sample(test, len(test))

"""EEG signals classification using the K-means clustering and a multilayer
perceptron neural network model (Umut Orhan 2011)
"""

#K-means clustering:
model = TimeSeriesKMeans(n_clusters=2, metric="softdtw", max_iter = 5)
model.fit(np.array(train))

pred = model.predict(np.array(test))
pred

a = np.zeros((320,), dtype=int)
b = np.ones((80,), dtype=int)
true = np.concatenate([a, b])

confusion_matrix(true, pred)

centers = model.cluster_centers_
centers = np.array([centers[0].flatten(), centers[1].flatten()])
centers

plt.plot(centers[0], color = 'red')
for dataset in [Z, O]:
    for i in range(1):
        plt.plot(dataset.iloc[:, i][0 : 1000], color = 'c')

plt.plot(centers[1], color = 'r')
for dataset in [N, F]:
    for i in range(1):
        plt.plot(dataset.iloc[:, i][0: 1000], color = 'c')

model.to_json("Model")

model = TimeSeriesKMeans.from_json('Model.txt')
model
pred = model.predict(test)
a = np.zeros((320,), dtype=int)
b = np.ones((80,), dtype=int)
true = np.concatenate([a, b])
confusion_matrix(true, pred)